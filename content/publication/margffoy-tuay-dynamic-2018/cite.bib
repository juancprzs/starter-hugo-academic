@inproceedings{margffoy-tuay_dynamic_2018,
 abstract = {We address the problem of segmenting an object given a natural language expression that describes it. Current techniques tackle this task by either (i) directly or recursively merging linguistic and visual information in the channel dimension and then performing convolutions; or by (ii) mapping the expression to a space in which it can be thought of as a filter, whose response is directly related to the presence of the object at a given spatial coordinate in the image, so that a convolution can be applied to look for the object. We propose a novel method that integrates these two insights in order to fully exploit the recursive nature of language. Additionally, during the upsampling process, we take advantage of the intermediate information generated when downsampling the image, so that detailed segmentations can be obtained. We compare our method against the state-of-the-art approaches in four standard datasets, in which it surpasses all previous methods in six of eight of the splits for this task.},
 author = {Margffoy-Tuay, Edgar and Pérez, Juan C. and Botero, Emilio and Arbeláez, Pablo},
 booktitle = {Proceedings of the European Conference on Computer Vision (ECCV)},
 file = {Margffoy-Tuay et al. - 2018 - Dynamic Multimodal Instance Segmentation Guided by.pdf:files/3/Margffoy-Tuay et al. - 2018 - Dynamic Multimodal Instance Segmentation Guided by.pdf:application/pdf},
 month = {September},
 title = {Dynamic Multimodal Instance Segmentation Guided by Natural Language Queries},
 year = {2018}
}

