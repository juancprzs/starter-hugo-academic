@inproceedings{castillo_generalized_2021,
 abstract = {Real-world Super-Resolution (SR) has been traditionally tackled by first learning a specific degradation model that resembles the noise and corruption artifacts in low-resolution imagery. Thus, current methods lack generalization and lose their accuracy when tested on unseen types of corruption. In contrast to the traditional proposal, we present Robust Super-Resolution (RSR), a method that leverages the generalization capability of adversarial attacks to tackle real-world SR. Our novel framework poses a paradigm shift in the development of real-world SR methods. Instead of learning a dataset-specific degradation, we employ adversarial attacks to create difficult examples that target the model's weaknesses. Afterward, we use these adversarial examples during training to improve our model's capacity to process noisy inputs. We perform extensive experimentation on synthetic and real-world images and empirically demonstrate that our RSR method generalizes well across datasets without re-training for specific noise priors. By using a single robust model, we outperform state-of-the-art specialized methods on real-world benchmarks.},
 author = {Castillo, Angela and Escobar, María and Pérez, Juan C. and Romero, Andrés and Timofte, Radu and Van Gool, Luc and Arbelaez, Pablo},
 booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV) Workshops},
 file = {Castillo et al. - 2021 - Generalized Real-World Super-Resolution Through Ad.pdf:files/15/Castillo et al. - 2021 - Generalized Real-World Super-Resolution Through Ad.pdf:application/pdf},
 month = {October},
 pages = {1855--1865},
 title = {Generalized Real-World Super-Resolution Through Adversarial Robustness},
 year = {2021}
}

