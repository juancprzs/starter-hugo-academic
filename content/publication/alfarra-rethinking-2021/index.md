---
title: Rethinking Clustering for Robustness
date: '2021-01-01'
draft: true
publishDate: '2022-01-24T12:51:35.643794Z'
authors:
- Motasem Alfarra
- Juan C. Pérez
- Adel Bibi
- Ali Thabet
- Pablo Arbeláez
- Bernard Ghanem
publication_types:
- '1'
abstract: 'This paper studies how encouraging semantically-aligned features during
  deep neural network training can increase network robustness. Recent works observed
  that Adversarial Training leads to robust models, whose learnt features appear to
  correlate with human perception. Inspired by this connection from robustness to
  semantics, we study the complementary connection: from semantics to robustness.
  To do so, we provide a robustness certificate for distance-based classification
  models (clustering-based classifiers). Moreover, we show that this certificate is
  tight, and we leverage it to propose ClusTR (Clustering Training for Robustness),
  a clustering-based and adversary-free training framework to learn robust models.
  Interestingly, ClusTR outperforms adversarially-trained networks by up to 4% under
  strong PGD attacks. Our code for reproducing our results can be found at https://github.com/rethinking-clustering-for-robustness.'
featured: false
publication: ''
---

